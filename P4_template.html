---
title: "Client Report - Can You Predict That?"
subtitle: "Course DS 250"
author: "[Ryan Matthews]"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *

# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL


url = https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv



from sklearn.tree import DecisionTreeClassifier


classifier_DT = DecisionTreeClassifier(max_depth=11)


classifier_DT.fit(X_train, y_train)


y_pred = classifier_DT.predict(X_test)


```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

We received all of this data from you, what we have concluded from your data is that the most important part of it is that most houses on this list were born after 1980 not before and that most houses are two stories or more. In the analysis, we will show you how we ordered the data.

## QUESTION|TASK 1

__Create 2-3 charts that evaluate potential relationships between the home variables and `before1980`.__ Explain what you learn from the charts that could help a machine learning algorithm. 

_type your results and analysis here_

```{python}
#Include and execute your code here


url = "https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv"
df = pd.read_csv(url)


df_pre1980 = df[df['yrbuilt'] < 1980]

sns.set(style="whitegrid")

# 1. Histogram of year built (before 1980)
plt.figure(figsize=(10, 5))
sns.histplot(df_pre1980['yrbuilt'], bins=30, kde=True, color='skyblue')
plt.title('Distribution of Year Built (Before 1980)')
plt.xlabel('Year Built')
plt.ylabel('Number of Houses')
plt.show()

# 2. Scatter plot: basement square footage vs. finished basement
plt.figure(figsize=(10, 5))
sns.scatterplot(data=df_pre1980, x='bsmtsf', y='finbsmnt', hue='quality')
plt.title('Basement SF vs Finished Basement (Before 1980)')
plt.xlabel('Basement Square Footage')
plt.ylabel('Finished Basement (1 = Yes, 0 = No)')
plt.legend(title='Quality Score', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# 3. Boxplot: Quality by decade
df_pre1980['decade'] = (df_pre1980['yrbuilt'] // 10) * 10
plt.figure(figsize=(10, 5))
sns.boxplot(data=df_pre1980, x='decade', y='quality')
plt.title('Quality Scores by Decade (Before 1980)')
plt.xlabel('Decade Built')
plt.ylabel('Quality Score')
plt.show()

```


## QUESTION|TASK 2

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”.__ Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.  

Below I created multiple charts, each that shoot for 90% accuracy, the random forest chart did the best with 90% accuracy.

```{python}
# Include and execute your code here

url <- "https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv"
df <- read_csv(url)

df <- df %>%
  mutate(label = ifelse(yrbuilt < 1980, "before_1980", "after_1980")) %>%
  select(-yrbuilt)  # Remove original column to avoid leakage

df <- df %>% select(-uniqueid)

df <- df %>% drop_na()
#Random Forest Chart
set.seed(42)
split <- createDataPartition(df$label, p = 0.8, list = FALSE)
train <- df[split, ]
test <- df[-split, ]

control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"

set.seed(42)
rf_model <- train(label ~ ., data = train, method = "rf",
                  trControl = control, metric = metric,
                  tuneLength = 5)

```


## QUESTION|TASK 3

__Justify your classification model by discussing the most important features selected by your model.__ This discussion should include a feature importance chart and a description of the features. 

_type your results and analysis here_

```{python}
# Include and execute your code here

url <- "https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv"
df <- read_csv(url)

df_labeled <- sqldf("
  SELECT *,
         CASE WHEN yrbuilt < 1980 THEN 'before_1980'
              ELSE 'after_1980' END AS label
  FROM df
")

df_clean <- sqldf("
  SELECT *
  FROM df_labeled
  WHERE yrbuilt IS NOT NULL
    AND bsmtsf IS NOT NULL
    AND finbsmnt IS NOT NULL
    AND quality IS NOT NULL
    AND no_use IS NOT NULL
    AND troom IS NOT NULL
    AND sprice IS NOT NULL
")
```


## QUESTION|TASK 4

__Describe the quality of your classification model using 2-3 different evaluation metrics.__ You also need to explain how to interpret each of the evaluation metrics you use.  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---

## STRETCH QUESTION|TASK 1

__Repeat the classification model using 3 different algorithms.__ Display their Feature Importance, and Decision Matrix. Explian the differences between the models and which one you would recommend to the Client.   

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 2

__Join the `dwellings_neighborhoods_ml.csv` data to the `dwelling_ml.csv` on the `parcel` column to create a new dataset. Duplicate the code for the stretch question above and update it to use this data.__ Explain the differences and if this changes the model you recomend to the Client.   

Accuracy: Overall fraction of correct predictions (both classes).
High accuracy (>90%) indicates good overall performance.

Precision: Of all houses predicted as 'before_1980', how many actually are.
High precision means few false positives — model is reliable when it predicts 'before_1980'.

Recall: Of all actual 'before_1980' houses, how many did the model correctly identify.
High recall means the model finds most older homes, minimizing false negatives.

Together, these metrics show balanced, robust classificati

```{python}
# Include and execute your code here



# 1. Load data
url = "https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv"
df = pd.read_csv(url)

# 2. Create binary label
df['label'] = np.where(df['yrbuilt'] < 1980, 'before_1980', 'after_1980')

# Drop columns that leak the target or are IDs
df = df.drop(columns=['yrbuilt', 'uniqueid'])

# Drop rows with missing values
df = df.dropna()

# 3. Prepare features and target
X = df.drop(columns=['label'])
y = df['label']

# 4. Train/Test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

# 5. Initialize models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
    'Random Forest': RandomForestClassifier(random_state=42)
}

# 6. Train, predict, and evaluate each model
results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    acc = accuracy_score(y_test, preds)
    prec = precision_score(y_test, preds, pos_label='before_1980')
    rec = recall_score(y_test, preds, pos_label='before_1980')
    
    results.append({
        'Model': name,
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec
    })

results_df = pd.DataFrame(results)
print("Model Performance Summary:\n")
print(results_df)

# 7. Feature importance from Random Forest
rf = models['Random Forest']

# Extract feature importances
feat_imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)

# Plot feature importance
plt.figure(figsize=(10,6))
sns.barplot(x=feat_imp.values, y=feat_imp.index, palette='viridis')
plt.title('Feature Importance - Random Forest')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()



```


## STRETCH QUESTION|TASK 3

__Can you build a model that predicts the year a house was built?__ Explain the model and the evaluation metrics you would use to determine if the model is good.  

_type your results and analysis here_

```{python}
# Include and execute your code here

url = "https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv"
df = pd.read_csv(url)

df = df.dropna()

X = df.drop(columns=['yrbuilt', 'uniqueid'])  # Drop target and ID
y = df['yrbuilt']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f} years")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f} years")
print(f"R-squared (R²): {r2:.3f}")

feat_importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x=feat_importances.values, y=feat_importances.index, palette='viridis')
plt.title('Feature Importance - Random Forest Regression')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()
```

---
